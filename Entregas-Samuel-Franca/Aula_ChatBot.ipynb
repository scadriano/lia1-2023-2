{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e51f3042"
      },
      "source": [
        "**Laboratório de Inovação e Automação 1 (LIA 1) - Aula ChatBot (15/11)**\n",
        "\n",
        "---\n",
        "\n",
        "**ALUNO:** Samuel França da Costa Pedrosa\n",
        "\n",
        "**MATRÍCULA:** 201900261\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-STBW191uSo",
        "outputId": "adeccbeb-2a87-483d-8f82-9822e68cab6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Obtendo a chave da API a partir das variáveis de ambiente\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Função para gerar texto a partir do modelo de linguagem\n",
        "def gera_texto(messages):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Função principal do programa em Python\n",
        "def main():\n",
        "    print(\"\\nBem-vindo ao GPT-4 Chatbot!\")\n",
        "    print(\"(Digite 'sair' a qualquer momento para encerrar o chat)\")\n",
        "\n",
        "    # Inicializando a lista de mensagens com a mensagem de boas-vindas\n",
        "    messages = [{\"role\": \"system\", \"content\": \"Você é um chatbot.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Oi!\"}]\n",
        "\n",
        "    while True:\n",
        "        # Coletando a pergunta digitada pelo usuário\n",
        "        user_message = input(\"\\nVocê: \").strip()\n",
        "\n",
        "        # Verificando se o usuário deseja sair\n",
        "        if user_message.lower() == \"sair\":\n",
        "            break\n",
        "\n",
        "        # Adicionando a mensagem do usuário à lista de mensagens\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "        # Obtendo a resposta do modelo\n",
        "        chatbot_response = gera_texto(messages)\n",
        "\n",
        "        # Adicionando a resposta do chatbot à lista de mensagens\n",
        "        messages.append({\"role\": \"assistant\", \"content\": chatbot_response})\n",
        "\n",
        "        # Imprimindo a resposta do chatbot\n",
        "        print(f\"\\nChatbot: {chatbot_response}\")"
      ],
      "metadata": {
        "id": "L-HCU1ib1ySN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando o programa\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXydSooU8Mpl",
        "outputId": "de71c2d4-78d8-4905-99f7-f95d7cf294e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bem-vindo ao GPT-4 Chatbot!\n",
            "(Digite 'sair' a qualquer momento para encerrar o chat)\n",
            "\n",
            "Você: ola\n",
            "\n",
            "Chatbot: Olá! Como posso ajudar você hoje?\n",
            "\n",
            "Você: quem é você?\n",
            "\n",
            "Chatbot: Eu sou um chatbot projetado para ajudar a responder suas perguntas e fornecer informações sobre uma variedade de tópicos. Posso te ajudar com algo específico?\n",
            "\n",
            "Você: sair\n"
          ]
        }
      ]
    }
  ]
}